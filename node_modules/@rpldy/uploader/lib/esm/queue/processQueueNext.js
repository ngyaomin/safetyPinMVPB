import { FILE_STATES, logger } from "@rpldy/shared";
import processBatchItems from "./processBatchItems";
import { getBatchDataFromItemId, getIsItemBatchReady, isNewBatchStarting, cancelBatchForItem, loadNewBatchForItem, isItemBelongsToBatch } from "./batchHelpers";

var getIsItemInActiveRequest = function (queue, itemId) {
  return !!~queue.getState().activeIds // $FlowFixMe - no flat
  .flat().indexOf(itemId);
};

var getIsItemReady = function (item) {
  return item.state === FILE_STATES.ADDED;
};

export var findNextItemIndex = function (queue) {
  var state = queue.getState(),
      itemQueue = state.itemQueue,
      items = state.items;
  var index = 0,
      nextId = itemQueue[index]; //find item that isnt already in an active request and belongs to a "ready" batch

  while (nextId && (getIsItemInActiveRequest(queue, nextId) || !getIsItemBatchReady(queue, nextId) || !getIsItemReady(items[nextId]))) {
    index += 1;
    nextId = itemQueue[index];
  }

  return nextId ? index : -1;
};
export var getNextIdGroup = function (queue) {
  var itemQueue = queue.getState().itemQueue;
  var nextItemIndex = findNextItemIndex(queue);
  var nextId = itemQueue[nextItemIndex],
      nextGroup;

  if (nextId) {
    var batchData = getBatchDataFromItemId(queue, nextId);
    var batchId = batchData.batch.id,
        groupMax = batchData.batchOptions.maxGroupSize || 0;

    if (batchData.batchOptions.grouped && groupMax > 1) {
      nextGroup = [];
      var nextBelongsToSameBatch = true; //dont group files from different batches

      while (nextGroup.length < groupMax && nextBelongsToSameBatch) {
        nextGroup.push(nextId);
        nextId = itemQueue[nextItemIndex + nextGroup.length];
        nextBelongsToSameBatch = nextId && isItemBelongsToBatch(queue, nextId, batchId);
      }
    } else {
      nextGroup = [nextId];
    }
  }

  return nextGroup;
};

var processNext = function (queue) {
  var ids = getNextIdGroup(queue);
  var resultP = Promise.resolve();

  if (ids) {
    var currentCount = queue.getCurrentActiveCount(),
        _queue$getOptions = queue.getOptions(),
        _queue$getOptions$con = _queue$getOptions.concurrent,
        concurrent = _queue$getOptions$con === void 0 ? 0 : _queue$getOptions$con,
        _queue$getOptions$max = _queue$getOptions.maxConcurrent,
        maxConcurrent = _queue$getOptions$max === void 0 ? 0 : _queue$getOptions$max;

    if (!currentCount || concurrent && currentCount < maxConcurrent) {
      logger.debugLog("uploader.processor: Processing next upload - ", {
        ids: ids,
        state: queue.getState(),
        currentCount: currentCount
      });
      var cancelled = false;
      var newBatchP = Promise.resolve(false);

      if (isNewBatchStarting(queue, ids[0])) {
        newBatchP = loadNewBatchForItem(queue, ids[0]).then(function (allowBatch) {
          cancelled = !allowBatch;

          if (cancelled) {
            cancelBatchForItem(queue, ids[0]);
            processNext(queue);
          }

          return cancelled;
        });
      }

      resultP = newBatchP.then(function (cancelled) {
        if (!cancelled) {
          processBatchItems(queue, ids, processNext);
        }
      });
    }
  }

  return resultP;
};

export default processNext;