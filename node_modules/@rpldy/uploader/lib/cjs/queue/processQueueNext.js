"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports["default"] = exports.getNextIdGroup = exports.findNextItemIndex = void 0;

var _shared = require("@rpldy/shared");

var _processBatchItems = _interopRequireDefault(require("./processBatchItems"));

var _batchHelpers = require("./batchHelpers");

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { "default": obj }; }

var getIsItemInActiveRequest = function (queue, itemId) {
  return !!~queue.getState().activeIds // $FlowFixMe - no flat
  .flat().indexOf(itemId);
};

var getIsItemReady = function (item) {
  return item.state === _shared.FILE_STATES.ADDED;
};

var findNextItemIndex = function (queue) {
  var state = queue.getState(),
      itemQueue = state.itemQueue,
      items = state.items;
  var index = 0,
      nextId = itemQueue[index]; //find item that isnt already in an active request and belongs to a "ready" batch

  while (nextId && (getIsItemInActiveRequest(queue, nextId) || !(0, _batchHelpers.getIsItemBatchReady)(queue, nextId) || !getIsItemReady(items[nextId]))) {
    index += 1;
    nextId = itemQueue[index];
  }

  return nextId ? index : -1;
};

exports.findNextItemIndex = findNextItemIndex;

var getNextIdGroup = function (queue) {
  var itemQueue = queue.getState().itemQueue;
  var nextItemIndex = findNextItemIndex(queue);
  var nextId = itemQueue[nextItemIndex],
      nextGroup;

  if (nextId) {
    var batchData = (0, _batchHelpers.getBatchDataFromItemId)(queue, nextId);
    var batchId = batchData.batch.id,
        groupMax = batchData.batchOptions.maxGroupSize || 0;

    if (batchData.batchOptions.grouped && groupMax > 1) {
      nextGroup = [];
      var nextBelongsToSameBatch = true; //dont group files from different batches

      while (nextGroup.length < groupMax && nextBelongsToSameBatch) {
        nextGroup.push(nextId);
        nextId = itemQueue[nextItemIndex + nextGroup.length];
        nextBelongsToSameBatch = nextId && (0, _batchHelpers.isItemBelongsToBatch)(queue, nextId, batchId);
      }
    } else {
      nextGroup = [nextId];
    }
  }

  return nextGroup;
};

exports.getNextIdGroup = getNextIdGroup;

var processNext = function (queue) {
  var ids = getNextIdGroup(queue);
  var resultP = Promise.resolve();

  if (ids) {
    var currentCount = queue.getCurrentActiveCount(),
        _queue$getOptions = queue.getOptions(),
        _queue$getOptions$con = _queue$getOptions.concurrent,
        concurrent = _queue$getOptions$con === void 0 ? 0 : _queue$getOptions$con,
        _queue$getOptions$max = _queue$getOptions.maxConcurrent,
        maxConcurrent = _queue$getOptions$max === void 0 ? 0 : _queue$getOptions$max;

    if (!currentCount || concurrent && currentCount < maxConcurrent) {
      _shared.logger.debugLog("uploader.processor: Processing next upload - ", {
        ids: ids,
        state: queue.getState(),
        currentCount: currentCount
      });

      var cancelled = false;
      var newBatchP = Promise.resolve(false);

      if ((0, _batchHelpers.isNewBatchStarting)(queue, ids[0])) {
        newBatchP = (0, _batchHelpers.loadNewBatchForItem)(queue, ids[0]).then(function (allowBatch) {
          cancelled = !allowBatch;

          if (cancelled) {
            (0, _batchHelpers.cancelBatchForItem)(queue, ids[0]);
            processNext(queue);
          }

          return cancelled;
        });
      }

      resultP = newBatchP.then(function (cancelled) {
        if (!cancelled) {
          (0, _processBatchItems["default"])(queue, ids, processNext);
        }
      });
    }
  }

  return resultP;
};

var _default = processNext;
exports["default"] = _default;